{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "317679ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import ndcg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2e6f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_impute_and_fe.process_A_srch import process_search_features_smoothed\n",
    "from data_impute_and_fe.process_B_prop import process_hotel_features\n",
    "from data_impute_and_fe.process_C_price import process_price_feature_smoothed\n",
    "from data_impute_and_fe.process_D_user import process_new_user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "CSV_PATH = \"../2/dmt-2025-2nd-assignment/training_set_VU_DM.csv\"\n",
    "reader = pd.read_csv(CSV_PATH,nrows=2_500_000)\n",
    "df = reader.copy()\n",
    "\n",
    "CSV_PATH2 = \"../2/dmt-2025-2nd-assignment/test_set_VU_DM.csv\"\n",
    "reader2 = pd.read_csv(CSV_PATH2)\n",
    "df2 = reader2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc472e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da263dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srch_id', 'visitor_location_country_id', 'visitor_hist_starrating',\n",
      "       'visitor_hist_adr_usd', 'prop_country_id', 'prop_id', 'prop_starrating',\n",
      "       'prop_review_score', 'prop_brand_bool', 'prop_location_score2',\n",
      "       'prop_log_historical_price', 'position', 'price_usd', 'promotion_flag',\n",
      "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
      "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
      "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv',\n",
      "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
      "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
      "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
      "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
      "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
      "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
      "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
      "       'comp8_rate_percent_diff', 'click_bool', 'gross_bookings_usd',\n",
      "       'booking_bool', 'total_guests', 'review_score_label',\n",
      "       'query_affinity_missing', 'historical_price_level', 'is_new_user'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# clean training set\n",
    "df_final, cols_A, cols_categorical_A = process_search_features_smoothed(df, drop_raw_columns=False)\n",
    "df_final, cols_B, cols_categorical_B = process_hotel_features(df_final, drop_raw_columns=False)\n",
    "df_df_finalc_clean, cols_C, cols_categorical_C = process_price_feature_smoothed(df_final, drop_raw_columns=False)\n",
    "df_final, cols_D, cols_categorical_D = process_new_user(df_final, drop_raw_columns=False)\n",
    "df = df_final.copy()\n",
    "print(df.columns)\n",
    "\n",
    "# clean test set\n",
    "df2_final, cols_A, cols_categorical_A = process_search_features_smoothed(df2, drop_raw_columns=False)  \n",
    "df2_final, cols_B, cols_categorical_B = process_hotel_features(df2_final, drop_raw_columns=False)\n",
    "df2_final, cols_C, cols_categorical_C = process_price_feature_smoothed(df2_final, drop_raw_columns=False)\n",
    "df2_final, cols_D, cols_categorical_D = process_new_user(df2_final, drop_raw_columns=False)\n",
    "df2 = df2_final.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b343488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define user features\n",
    "user_features = [\n",
    "    \"visitor_location_country_id\",\n",
    "    \"srch_destination_id\",\n",
    "]\n",
    "df_groupable = df.dropna(subset=user_features + ['prop_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c9987a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['srch_id', 'visitor_location_country_id', 'visitor_hist_starrating',\n",
      "       'visitor_hist_adr_usd', 'prop_country_id', 'prop_id', 'prop_starrating',\n",
      "       'prop_review_score', 'prop_brand_bool', 'prop_location_score2',\n",
      "       'prop_log_historical_price', 'price_usd', 'promotion_flag',\n",
      "       'srch_destination_id', 'srch_length_of_stay', 'srch_booking_window',\n",
      "       'srch_saturday_night_bool', 'srch_query_affinity_score',\n",
      "       'orig_destination_distance', 'random_bool', 'comp1_rate', 'comp1_inv',\n",
      "       'comp1_rate_percent_diff', 'comp2_rate', 'comp2_inv',\n",
      "       'comp2_rate_percent_diff', 'comp3_rate', 'comp3_inv',\n",
      "       'comp3_rate_percent_diff', 'comp4_rate', 'comp4_inv',\n",
      "       'comp4_rate_percent_diff', 'comp5_rate', 'comp5_inv',\n",
      "       'comp5_rate_percent_diff', 'comp6_rate', 'comp6_inv',\n",
      "       'comp6_rate_percent_diff', 'comp7_rate', 'comp7_inv',\n",
      "       'comp7_rate_percent_diff', 'comp8_rate', 'comp8_inv',\n",
      "       'comp8_rate_percent_diff', 'total_guests', 'review_score_label',\n",
      "       'query_affinity_missing', 'historical_price_level', 'is_new_user',\n",
      "       'sim_user_click_rate', 'sim_user_book_rate'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# aggregate user features to get click and booking rates\n",
    "agg = df_groupable.groupby(user_features + ['prop_id']).agg(\n",
    "    sim_user_click_rate=('click_bool', 'mean'),\n",
    "    sim_user_book_rate=('booking_bool', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# merge back to the original dataframe\n",
    "df = df.merge(agg, on=user_features + ['prop_id'], how='left') # train\n",
    "df2 = df2.merge(agg, on=user_features + ['prop_id'], how='left') # test\n",
    "print(df2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ea17e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the missing values\n",
    "df['sim_user_click_rate'] = df['sim_user_click_rate'].fillna(0)\n",
    "df['sim_user_book_rate'] = df['sim_user_book_rate'].fillna(0)\n",
    "df2['sim_user_click_rate'] = df2['sim_user_click_rate'].fillna(0)\n",
    "df2['sim_user_book_rate'] = df2['sim_user_book_rate'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7ef888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_weight(df, booking_label, click_label, booking_weight, click_weight, default_weight):\n",
    "    \"\"\"\n",
    "    This function assigns weights to the labels based on the number of clicks and bookings\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['label'] = df['booking_bool'] * booking_label + df['click_bool'] * click_label\n",
    "    \n",
    "    # assign weight according to the label\n",
    "    df['weight'] = default_weight\n",
    "    df.loc[(df['click_bool'] == 1) & (df['booking_bool'] == 0), 'weight'] = click_weight\n",
    "    df.loc[df['booking_bool'] == 1, 'weight'] = booking_weight\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e5263a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0     95513\n",
      "15     2791\n",
      "5      1696\n",
      "Name: count, dtype: int64\n",
      "Train set size: (94629, 57)\n",
      "Validation set size: (5371, 57)\n"
     ]
    }
   ],
   "source": [
    "# combined labels for click an booking\n",
    "booking_label = 10\n",
    "click_label = 5\n",
    "booking_weight = 10\n",
    "click_weight = 5\n",
    "default_weight = 1\n",
    "df_labeled = assign_weight(df, booking_label, click_label, booking_weight, click_weight, default_weight)\n",
    "\n",
    "# group search session by user id\n",
    "unique_searches = df['srch_id'].unique()\n",
    "\n",
    "# split the train and test set\n",
    "search_train, search_va = train_test_split(unique_searches, test_size=0.05, random_state=42)\n",
    "\n",
    "# create a train and test dataset\n",
    "train_df = df_labeled[df_labeled['srch_id'].isin(search_train)].sort_values('srch_id')\n",
    "val_df  = df_labeled[df_labeled['srch_id'].isin(search_va)].sort_values('srch_id')\n",
    "\n",
    "print(df_labeled['label'].value_counts())\n",
    "print(f\"Train set size: {train_df.shape}\")\n",
    "print(f\"Validation set size: {val_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce5e46a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group train size: 94629\n",
      "X_train size: (94629, 14)\n"
     ]
    }
   ],
   "source": [
    "# prepare the input and labels for the model\n",
    "features = [\n",
    "        \"srch_length_of_stay\",\n",
    "        \"srch_booking_window\",\n",
    "        \"total_guests\",\n",
    "        \"srch_saturday_night_bool\",\n",
    "        \"prop_review_score\",\n",
    "        \"prop_starrating\",\n",
    "        \"price_usd\",\n",
    "        \"promotion_flag\",\n",
    "        \"prop_brand_bool\",\n",
    "        \"prop_log_historical_price\",\n",
    "        \"historical_price_level\",\n",
    "        \"review_score_label\",\n",
    "        \"sim_user_click_rate\",\n",
    "        \"sim_user_book_rate\",\n",
    "        ]\n",
    "X_train = train_df[features]\n",
    "X_val = val_df[features]\n",
    "y_train = train_df['label']\n",
    "y_val = val_df['label'] \n",
    "group_train = train_df.groupby('srch_id').size().to_list()\n",
    "\n",
    "# these two parts should have the same size\n",
    "print(f\"Group train size: {sum(group_train)}\")\n",
    "print(f\"X_train size: {X_train.shape}\")\n",
    "\n",
    "# create a validation set\n",
    "val_group = val_df.groupby('srch_id').size().to_list()\n",
    "val_set = lgb.Dataset(X_val, label=y_val,group=val_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6aa2593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Calculating query weights...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 842\n",
      "[LightGBM] [Info] Number of data points in the train set: 94629, number of used features: 14\n"
     ]
    }
   ],
   "source": [
    "# train the models\n",
    "params = {\n",
    "    \"objective\": \"lambdarank\",\n",
    "    \"metric\": \"ndcg\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbose\": 1,\n",
    "}\n",
    "train_data = lgb.Dataset(X_train, label=y_train, weight = train_df['weight'], group=group_train)\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, val_set],\n",
    "    valid_names=['train', 'valid'],\n",
    "    num_boost_round=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e99cf920",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    srch_id  prop_id      score  rank\n",
      "14        1    72090  31.876518   1.0\n",
      "0         1     3180  31.734204   2.0\n",
      "1         1     5543  30.234303   3.0\n",
      "3         1    22393  30.007148   4.0\n",
      "6         1    34263  29.931554   5.0\n",
      "22        1    95031  29.916733   6.0\n",
      "28        1   139162  29.819018   7.0\n",
      "17        1    78599  29.735594   8.0\n",
      "13        1    63894  29.719202   9.0\n",
      "18        1    82231  29.683274  10.0\n",
      "23        1    99484  29.606237  11.0\n",
      "4         1    24194  29.281695  12.0\n",
      "16        1    74045  29.199996  13.0\n",
      "15        1    73666  28.648356  14.0\n",
      "5         1    28181  28.595128  15.0\n",
      "20        1    90385  28.535879  16.0\n",
      "24        1   123675  28.495206  17.0\n",
      "21        1    94729  28.362105  18.0\n",
      "9         1    54937  28.253016  19.0\n",
      "2         1    14142  28.227429  20.0\n"
     ]
    }
   ],
   "source": [
    "# prediction on the test set\n",
    "X_test = df2[features]\n",
    "df2['score'] = model.predict(X_test)\n",
    "df2['rank'] = df2.groupby('srch_id')['score'].rank(ascending=False)\n",
    "output = df2[['srch_id', 'prop_id', 'score', 'rank']].sort_values(['srch_id', 'rank'])\n",
    "print(output.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec727d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit Rate: 0.5813\n",
      "NDCG@5: 0.9205\n"
     ]
    }
   ],
   "source": [
    "# evaluate the ranking \n",
    "val_df['score'] = model.predict(X_val)\n",
    "val_df['rank'] = val_df.groupby('srch_id')['score'].rank(ascending=False, method='first')\n",
    "\n",
    "# Step 6: Evaluate Hit@1 and NDCG@5\n",
    "top_preds = val_df[val_df['rank'] == 1]\n",
    "hit_rate = (top_preds['booking_bool'] == 1).mean()\n",
    "\n",
    "ndcg_list = []\n",
    "for srch_id, group in val_df.groupby('srch_id'):\n",
    "    y_true = group['label'].values.reshape(1, -1)\n",
    "    y_score = group['score'].values.reshape(1, -1)\n",
    "    ndcg = ndcg_score(y_true, y_score, k=5)\n",
    "    ndcg_list.append(ndcg)\n",
    "average_ndcg = np.mean(ndcg_list)\n",
    "print(f\"Hit Rate: {hit_rate:.4f}\")\n",
    "print(f\"NDCG@5: {average_ndcg:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48c1dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the output as a csv file\n",
    "submission = output[['srch_id', 'prop_id']].copy()\n",
    "submission.to_csv('hotel_ranking_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b1dc08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
