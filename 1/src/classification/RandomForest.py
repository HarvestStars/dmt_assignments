import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# === Step 1: å¯¼å…¥è®­ç»ƒå’Œæµ‹è¯•é›† ===
train_df = pd.read_csv("./source_data/train_split_by_id.csv")
test_df = pd.read_csv("./source_data/test_split_by_id.csv")

# === Step 2: å®šä¹‰ç‰¹å¾åˆ—ä¸ç›®æ ‡åˆ— ===
# é»˜è®¤é€‰æ‹©æ‰€æœ‰ä»¥ `_hist_mean` ç»“å°¾çš„åˆ—ä½œä¸ºç‰¹å¾
features = [col for col in train_df.columns if col.endswith('_hist_mean')]
target = 'mood_type'

X_train = train_df[features]
y_train = train_df[target]
X_test = test_df[features]
y_test = test_df[target]

# === Step 3: è®­ç»ƒåˆ†ç±»æ¨¡å‹ï¼ˆä»¥ Random Forest ä¸ºä¾‹ï¼‰ ===
clf = RandomForestClassifier(random_state=42)
clf.fit(X_train, y_train)

# === Step 4: è¿›è¡Œé¢„æµ‹ ===
y_pred = clf.predict(X_test)

# === Step 5: è¯„ä¼°æŒ‡æ ‡ ===
acc = accuracy_score(y_test, y_pred)
mae = mean_absolute_error(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
report = classification_report(y_test, y_pred)

# === Step 6: æ‰“å°ç»“æœ ===
print("âœ… Accuracy:", acc)
print("ğŸ“‰ MAE:", mae)
print("ğŸ“‰ MSE:", mse)
print("\nğŸ“‹ Classification Report:\n", report)

# === Step 7: å¯è§†åŒ–æ··æ·†çŸ©é˜µ ===
# æ··æ·†çŸ©é˜µ
cm = confusion_matrix(y_test, y_pred, labels=[0, 1])
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Low (<7)", "High (â‰¥7)"])
disp.plot(cmap="Blues", values_format='d')

# è¯„ä¼°æŒ‡æ ‡
print("Accuracy:", accuracy_score(y_test, y_pred))
print("MAE:", mean_absolute_error(y_test, y_pred))
print("MSE:", mean_squared_error(y_test, y_pred))
print("\nClassification Report:\n", classification_report(y_test, y_pred, target_names=["Low (<7)", "High (â‰¥7)"]))

# ç»Ÿè®¡å„ç±»åˆ«æ•°é‡ï¼ˆçœŸå®å’Œé¢„æµ‹ï¼‰
actual_counts = pd.Series(y_test).value_counts().sort_index()
pred_counts = pd.Series(y_pred).value_counts().sort_index()

# ç¡®ä¿ä¸¤ä¸ª Series æœ‰ç›¸åŒç´¢å¼•ï¼ˆ0 å’Œ 1ï¼‰
all_classes = [0, 1]
actual_counts = actual_counts.reindex(all_classes, fill_value=0)
pred_counts = pred_counts.reindex(all_classes, fill_value=0)

# åˆå¹¶åˆ°ä¸€ä¸ª DataFrame
compare_df = pd.DataFrame({
    'Actual': actual_counts,
    'Predicted': pred_counts
})

# ç»˜å›¾
compare_df.plot(kind='bar', figsize=(7, 5), color=['orange', 'steelblue'])
plt.title("Random Forest \nActual vs Predicted Class Counts (Test Set)", fontsize=16)
plt.xlabel("Mood Type (Binary)", fontsize=16)
plt.ylabel("Count", fontsize=16)
plt.xticks(ticks=[0, 1], labels=["Low (<7)", "High (â‰¥7)"], rotation=0, fontsize=14)
plt.grid(axis='y')
plt.tight_layout()
plt.savefig("../../figs/actual_vs_predicted_counts.png", dpi=300)
plt.show()